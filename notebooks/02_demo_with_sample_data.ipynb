{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f382fb47",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.models.basic_cbm import ConceptBottleneckModel\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee52fa",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data\n",
    "\n",
    "We have 3 sample cases:\n",
    "- Case 1: Basal Cell Carcinoma (benign)\n",
    "- Case 577: Melanoma (malignant)\n",
    "- Case 578: Melanoma (malignant)\n",
    "\n",
    "Each case includes:\n",
    "- Clinical photograph\n",
    "- Dermoscopic image\n",
    "- 7-point checklist annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "with open('sample_data_derm7pt/cases_metadata.json', 'r') as f:\n",
    "    cases = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(cases)} sample cases:\\n\")\n",
    "\n",
    "for case in cases:\n",
    "    print(f\"Case {case['case_num']}: {case['diagnosis']}\")\n",
    "    print(f\"  Location: {case['metadata']['location']}\")\n",
    "    print(f\"  7-point score: {case['clinical_features']['seven_point']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559eb664",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Cases\n",
    "\n",
    "Let's look at the dermoscopic images and their concept annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd761ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, case in enumerate(cases):\n",
    "    # Load dermoscopic image\n",
    "    img_path = f\"sample_data_derm7pt/{case['dermoscopic_img']}\"\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f\"Case {case['case_num']}\\n{case['diagnosis']}\", fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/sample_cases.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample cases visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109de01a",
   "metadata": {},
   "source": [
    "## 4. Understanding the 7-Point Checklist\n",
    "\n",
    "The 7-point checklist is a standardized method for melanoma diagnosis:\n",
    "\n",
    "1. **Atypical Pigment Network** - Irregular brown lines\n",
    "2. **Blue-Whitish Veil** - Blue-white coloration\n",
    "3. **Atypical Vascular Pattern** - Irregular blood vessels\n",
    "4. **Irregular Streaks** - Linear structures at edges\n",
    "5. **Irregular Pigmentation** - Uneven coloring\n",
    "6. **Irregular Dots/Globules** - Round structures\n",
    "7. **Regression Structures** - White/blue areas from healing\n",
    "\n",
    "Each feature can be present (1) or absent (0), creating interpretable concepts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract concepts from case 578 (the melanoma with highest score)\n",
    "case_578 = [c for c in cases if c['case_num'] == 578][0]\n",
    "\n",
    "concept_names = [\n",
    "    \"Atypical Pigment Network\",\n",
    "    \"Blue-Whitish Veil\",\n",
    "    \"Atypical Vascular\",\n",
    "    \"Irregular Streaks\",\n",
    "    \"Irregular Pigmentation\",\n",
    "    \"Irregular Dots/Globules\",\n",
    "    \"Regression Structures\"\n",
    "]\n",
    "\n",
    "features = case_578['clinical_features']\n",
    "concepts = [\n",
    "    1 if features['pigment_network'] == 'atypical' else 0,\n",
    "    1 if features['blue_whitish_veil'] == 'present' else 0,\n",
    "    1 if features['vascular_structures'] in ['atypical', 'arborizing'] else 0,\n",
    "    1 if features['streaks'] == 'irregular' else 0,\n",
    "    1 if features['pigmentation'] in ['irregular', 'localized in'] else 0,\n",
    "    1 if features['dots_and_globules'] == 'irregular' else 0,\n",
    "    1 if features['regression'] in ['combination', 'white areas'] else 0,\n",
    "]\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if c == 1 else 'lightgray' for c in concepts]\n",
    "plt.barh(range(7), concepts, color=colors)\n",
    "plt.yticks(range(7), concept_names)\n",
    "plt.xlabel('Present (1) or Absent (0)')\n",
    "plt.title(f'Case {case_578[\"case_num\"]} - {case_578[\"diagnosis\"]}\\n7-Point Checklist Annotations')\n",
    "plt.xlim([0, 1.2])\n",
    "for i, v in enumerate(concepts):\n",
    "    plt.text(v + 0.05, i, 'Present' if v == 1 else 'Absent', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/case_578_concepts.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Case 578 has {sum(concepts)}/7 features present → High risk for melanoma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e6415",
   "metadata": {},
   "source": [
    "## 5. Initialize a Concept Bottleneck Model\n",
    "\n",
    "Let's create a CBM with:\n",
    "- **ResNet50** backbone for feature extraction\n",
    "- **7 concept predictors** (one per checklist item)\n",
    "- **Linear task predictor** for diagnosis (interpretable!)\n",
    "\n",
    "**Note**: This model is untrained, so predictions will be random. \n",
    "For a trained model, run `python examples/train_basic_cbm.py --data_path /home/xrai/datasets/derm7pt/release_v0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26108c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ConceptBottleneckModel(\n",
    "    num_concepts=7,\n",
    "    num_classes=2,\n",
    "    backbone='resnet50',\n",
    "    pretrained=True  # Use pretrained ImageNet weights\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "concept_params = sum(p.numel() for p in model.concept_encoder.parameters())\n",
    "task_params = sum(p.numel() for p in model.task_predictor.parameters())\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Concept encoder: {concept_params:,}\")\n",
    "print(f\"  Task predictor: {task_params:,}\")\n",
    "print(f\"\\nModel structure:\")\n",
    "print(f\"  Input: [batch, 3, 224, 224] image\")\n",
    "print(f\"  → Concept Encoder → [batch, 7] concepts\")\n",
    "print(f\"  → Task Predictor → [batch, 2] logits (benign vs malignant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01909022",
   "metadata": {},
   "source": [
    "## 6. Run Inference on Sample Cases\n",
    "\n",
    "Let's see what the model predicts (even though it's untrained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abce059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Process all cases\n",
    "results = []\n",
    "\n",
    "for case in cases:\n",
    "    # Load image\n",
    "    img_path = f\"sample_data_derm7pt/{case['dermoscopic_img']}\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        pred_concepts, pred_logits = model(img_tensor)\n",
    "    \n",
    "    pred_probs = torch.softmax(pred_logits, dim=1)\n",
    "    pred_label = pred_probs[0, 1].item()  # Probability of malignant\n",
    "    \n",
    "    results.append({\n",
    "        'case': case,\n",
    "        'concepts': pred_concepts[0].tolist(),\n",
    "        'diagnosis_prob': pred_label\n",
    "    })\n",
    "    \n",
    "    print(f\"Case {case['case_num']}: {case['diagnosis']}\")\n",
    "    print(f\"  Model prediction: {'Malignant' if pred_label > 0.5 else 'Benign'} ({pred_label:.3f})\")\n",
    "    print(f\"  Concept predictions: {[f'{c:.3f}' for c in pred_concepts[0].tolist()][:3]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ Inference complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb550d",
   "metadata": {},
   "source": [
    "## 7. Visualize Concept Predictions\n",
    "\n",
    "Let's compare the model's concept predictions with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one case in detail\n",
    "case_idx = 2  # Case 578 (melanoma with all features)\n",
    "result = results[case_idx]\n",
    "case = result['case']\n",
    "\n",
    "# Extract ground truth concepts\n",
    "features = case['clinical_features']\n",
    "gt_concepts = [\n",
    "    1 if features['pigment_network'] == 'atypical' else 0,\n",
    "    1 if features['blue_whitish_veil'] == 'present' else 0,\n",
    "    1 if features['vascular_structures'] in ['atypical', 'arborizing'] else 0,\n",
    "    1 if features['streaks'] == 'irregular' else 0,\n",
    "    1 if features['pigmentation'] in ['irregular', 'localized in'] else 0,\n",
    "    1 if features['dots_and_globules'] == 'irregular' else 0,\n",
    "    1 if features['regression'] in ['combination', 'white areas'] else 0,\n",
    "]\n",
    "\n",
    "pred_concepts = result['concepts']\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Ground truth\n",
    "colors_gt = ['red' if c == 1 else 'lightgray' for c in gt_concepts]\n",
    "axes[0].barh(range(7), gt_concepts, color=colors_gt)\n",
    "axes[0].set_yticks(range(7))\n",
    "axes[0].set_yticklabels(concept_names, fontsize=10)\n",
    "axes[0].set_xlabel('Value')\n",
    "axes[0].set_title(f'Ground Truth Concepts\\nCase {case[\"case_num\"]}: {case[\"diagnosis\"]}')\n",
    "axes[0].set_xlim([0, 1.2])\n",
    "\n",
    "# Predictions\n",
    "colors_pred = ['green' if c > 0.5 else 'lightgray' for c in pred_concepts]\n",
    "axes[1].barh(range(7), pred_concepts, color=colors_pred)\n",
    "axes[1].set_yticks(range(7))\n",
    "axes[1].set_yticklabels(concept_names, fontsize=10)\n",
    "axes[1].set_xlabel('Probability')\n",
    "axes[1].set_title(f'Model Predictions (Untrained)\\nDiagnosis: {\"Malignant\" if result[\"diagnosis_prob\"] > 0.5 else \"Benign\"} ({result[\"diagnosis_prob\"]:.3f})')\n",
    "axes[1].set_xlim([0, 1.2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'outputs/case_{case[\"case_num\"]}_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Comparison saved for case {case['case_num']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d91cb",
   "metadata": {},
   "source": [
    "## 8. Understanding Concept Intervention\n",
    "\n",
    "The key advantage of CBMs: we can **intervene on concepts**!\n",
    "\n",
    "If the model gets a concept wrong, we can:\n",
    "1. Correct it manually\n",
    "2. Re-run the task predictor with corrected concepts\n",
    "3. Get a better diagnosis\n",
    "\n",
    "Let's demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take case 578 (melanoma)\n",
    "case = cases[2]\n",
    "img_path = f\"sample_data_derm7pt/{case['dermoscopic_img']}\"\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "# Original prediction\n",
    "with torch.no_grad():\n",
    "    original_concepts, original_logits = model(img_tensor)\n",
    "    original_prob = torch.softmax(original_logits, dim=1)[0, 1].item()\n",
    "\n",
    "print(\"BEFORE INTERVENTION:\")\n",
    "print(f\"  Predicted concepts: {[f'{c:.3f}' for c in original_concepts[0].tolist()]}\")\n",
    "print(f\"  Diagnosis probability (malignant): {original_prob:.3f}\")\n",
    "print(f\"  Prediction: {'Malignant' if original_prob > 0.5 else 'Benign'}\")\n",
    "print()\n",
    "\n",
    "# Simulate intervention: set all concepts to ground truth\n",
    "corrected_concepts = original_concepts.clone()\n",
    "gt_concepts_tensor = torch.tensor([[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]], dtype=torch.float32)\n",
    "corrected_concepts = gt_concepts_tensor\n",
    "\n",
    "# Re-predict with corrected concepts\n",
    "with torch.no_grad():\n",
    "    corrected_logits = model.predict_from_concepts(corrected_concepts)\n",
    "    corrected_prob = torch.softmax(corrected_logits, dim=1)[0, 1].item()\n",
    "\n",
    "print(\"AFTER INTERVENTION (corrected all concepts):\")\n",
    "print(f\"  Corrected concepts: {[f'{c:.3f}' for c in corrected_concepts[0].tolist()]}\")\n",
    "print(f\"  Diagnosis probability (malignant): {corrected_prob:.3f}\")\n",
    "print(f\"  Prediction: {'Malignant' if corrected_prob > 0.5 else 'Benign'}\")\n",
    "print()\n",
    "\n",
    "print(f\"Change in diagnosis probability: {corrected_prob - original_prob:+.3f}\")\n",
    "print(\"\\n✓ This demonstrates how human expertise can improve predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a38003",
   "metadata": {},
   "source": [
    "## 9. Inspect Task Predictor Weights\n",
    "\n",
    "Since we use a linear task predictor, we can see exactly how much each concept contributes to the diagnosis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4caf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the linear layer weights\n",
    "task_weights = model.task_predictor.weight.detach().numpy()\n",
    "\n",
    "# Weight for malignant class (index 1)\n",
    "malignant_weights = task_weights[1, :]\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if w > 0 else 'blue' for w in malignant_weights]\n",
    "plt.barh(range(7), malignant_weights, color=colors)\n",
    "plt.yticks(range(7), concept_names)\n",
    "plt.xlabel('Weight')\n",
    "plt.title('Task Predictor Weights for Malignant Class\\n(Positive = increases malignant probability)')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/task_predictor_weights.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Task Predictor Analysis:\")\n",
    "print(f\"  Most important concept: {concept_names[np.argmax(np.abs(malignant_weights))]}\")\n",
    "print(f\"  Weight: {malignant_weights[np.argmax(np.abs(malignant_weights))]:.3f}\")\n",
    "print(\"\\n  All weights:\")\n",
    "for name, weight in zip(concept_names, malignant_weights):\n",
    "    print(f\"    {name:.<40} {weight:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28253359",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "**What we learned:**\n",
    "\n",
    "1. ✅ **CBM Structure**: Image → Concepts → Diagnosis\n",
    "2. ✅ **7-Point Checklist**: Interpretable clinical concepts\n",
    "3. ✅ **Concept Predictions**: Binary features that doctors understand\n",
    "4. ✅ **Intervention**: Can correct wrong concepts to improve diagnosis\n",
    "5. ✅ **Interpretable Weights**: Linear predictor shows exact contribution\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Train a full model**: Run `python examples/train_basic_cbm.py --data_path /home/xrai/datasets/derm7pt/release_v0`\n",
    "2. **Evaluate on test set**: See how well concepts align with expert annotations\n",
    "3. **Information theory analysis**: Measure concept completeness and synergy\n",
    "4. **Compare architectures**: Try different backbones (EfficientNet, Vision Transformers)\n",
    "\n",
    "**Key Insight**: CBMs trade ~5% accuracy for full interpretability and intervention capability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory summary\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "print(\"✅ Demo complete!\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - outputs/sample_cases.png\")\n",
    "print(\"  - outputs/case_578_concepts.png\")\n",
    "print(f\"  - outputs/case_{cases[2]['case_num']}_comparison.png\")\n",
    "print(\"  - outputs/task_predictor_weights.png\")\n",
    "print(\"\\nTo train a full model, run:\")\n",
    "print(\"  python examples/train_basic_cbm.py --data_path /home/xrai/datasets/derm7pt/release_v0 --epochs 50\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
